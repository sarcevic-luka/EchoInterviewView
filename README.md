# EchoInterview

### Your AI-Powered Interview Practice Companion ğŸ¤ğŸ§ 

Practice makes perfect, and **EchoInterview** is here to help you nail that next job interview! This iOS app lets you rehearse interview questions, get real-time speech analysis, and receive AI-generated feedback â€” all from the comfort of your iPhone.

---

## What Does It Do? ğŸ¤”

Ever felt nervous before an interview? EchoInterview acts as your personal interview coach:

1. **Asks You Questions** â€” The app generates contextual interview questions (powered by on-device AI when available)
2. **Listens to Your Answers** â€” Real-time speech-to-text transcription captures what you say
3. **Analyzes Your Response** â€” NLP metrics evaluate clarity, pace, filler words, and more
4. **Scores Your Performance** â€” A CoreML model rates your answer quality
5. **Gives You Tips** â€” AI-generated coaching suggestions help you improve

Think of it as having a patient interviewer who never judges, always provides constructive feedback, and is available 24/7!

---

## Features âœ¨

| Feature | Description |
|---------|-------------|
| ğŸ™ï¸ **Speech Recognition** | Real-time transcription of your spoken answers |
| ğŸ—£ï¸ **Text-to-Speech** | Questions are read aloud with customizable voice & speed |
| ğŸ“Š **NLP Analysis** | Measures word count, speech rate, filler words, sentence structure |
| ğŸ¤– **ML Scoring** | CoreML model evaluates answer quality across multiple dimensions |
| ğŸ’¡ **AI Coaching** | Foundation Models generate personalized improvement tips |
| ğŸ“ˆ **Analytics Dashboard** | Visual breakdown of your performance with score charts |
| ğŸ“š **Session History** | SwiftData persistence stores all your practice sessions |
| âš™ï¸ **Customizable Settings** | Choose your preferred voice, adjust speech rate |
| ğŸ¨ **Animated UI** | Smooth waveform animations and haptic feedback |
| ğŸš€ **Onboarding Flow** | Guided setup for permissions and voice testing |

---

## Screenshots ğŸ“±
<img width="330" height="717" alt="Simulator Screenshot - iPhone 17 Pro Max - 2026-02-01 at 21 08 35" src="https://github.com/user-attachments/assets/5d657446-d6ae-425e-89c0-2640b17c3a10" />

<img width="330" height="717" alt="Simulator Screenshot - iPhone 17 Pro Max - 2026-02-01 at 21 08 57" src="https://github.com/user-attachments/assets/7af67f77-d35f-4aba-aa9f-41615d6614d2" />

<img width="330" height="717" alt="Simulator Screenshot - iPhone 17 Pro Max - 2026-02-01 at 21 09 26" src="https://github.com/user-attachments/assets/ea2fd918-3830-46f1-b563-eed7466ef423" />

---

## Tech Talk ğŸ› ï¸

EchoInterview is built with modern Swift and SwiftUI, following best practices for iOS 17+ development.

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Views                          â”‚
â”‚  (SwiftUI, declarative UI, animations)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                   ViewModels                        â”‚
â”‚  (@Observable, @MainActor, business logic)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    Services                         â”‚
â”‚  (Actors, protocol-based, dependency injection)     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                Apple Frameworks                     â”‚
â”‚  (Speech, AVFoundation, CoreML, SwiftData, etc.)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Technical Highlights

- **MVVM Architecture** â€” Clean separation with `@Observable` ViewModels
- **Swift Concurrency** â€” Async/await throughout, actor-isolated services
- **Protocol-Oriented** â€” All services defined by protocols for testability
- **Dependency Injection** â€” ServiceContainer provides dependencies
- **No Singletons in Views** â€” Dependencies passed explicitly
- **SwiftData** â€” Modern persistence for session history
- **CoreML** â€” On-device ML model for answer scoring
- **Foundation Models** â€” Apple's on-device LLM for question/tip generation
- **Zero Force Unwraps** â€” Safe optional handling everywhere

### Frameworks & Technologies Used

| Technology | Purpose |
|------------|---------|
| **SwiftUI** | Declarative UI with animations |
| **Swift Concurrency** | Async/await, actors, structured concurrency |
| **Speech Framework** | Real-time speech recognition |
| **AVFoundation** | Audio recording and text-to-speech |
| **NaturalLanguage** | NLP analysis (tokenization, embeddings) |
| **CoreML** | Machine learning model inference |
| **Foundation Models** | On-device LLM (iOS 18+) |
| **SwiftData** | Persistence layer |
| **os.log** | Structured logging |

### Project Structure

```
EchoInterview/
â”œâ”€â”€ Core/
â”‚   â”œâ”€â”€ AppState.swift          # Global app state
â”‚   â””â”€â”€ Router.swift            # Navigation management
â”œâ”€â”€ Models/
â”‚   â”œâ”€â”€ Answer.swift            # Answer data model
â”‚   â”œâ”€â”€ Question.swift          # Question data model
â”‚   â”œâ”€â”€ NLPMetrics.swift        # NLP analysis results
â”‚   â”œâ”€â”€ AnswerScores.swift      # Scoring results
â”‚   â””â”€â”€ InterviewSessionEntity.swift  # SwiftData entity
â”œâ”€â”€ Services/
â”‚   â”œâ”€â”€ AudioService.swift      # Microphone recording
â”‚   â”œâ”€â”€ SpeechRecognitionService.swift  # Speech-to-text
â”‚   â”œâ”€â”€ TextToSpeechService.swift       # Text-to-speech
â”‚   â”œâ”€â”€ NLPAnalysisService.swift        # NLP processing
â”‚   â”œâ”€â”€ ScoringProtocol.swift   # Scoring abstraction
â”‚   â”œâ”€â”€ CoreMLScoringService.swift      # ML-based scoring
â”‚   â”œâ”€â”€ SimpleScoringService.swift      # Fallback scoring
â”‚   â”œâ”€â”€ LLMService.swift        # AI question/tip generation
â”‚   â”œâ”€â”€ PersistenceService.swift        # SwiftData operations
â”‚   â””â”€â”€ ServiceContainer.swift  # Dependency container
â”œâ”€â”€ ViewModels/
â”‚   â”œâ”€â”€ InterviewSessionViewModel.swift
â”‚   â”œâ”€â”€ AnalyticsViewModel.swift
â”‚   â”œâ”€â”€ HistoryViewModel.swift
â”‚   â””â”€â”€ SettingsViewModel.swift
â”œâ”€â”€ Views/
â”‚   â”œâ”€â”€ InterviewRoomView.swift
â”‚   â”œâ”€â”€ AnalyticsView.swift
â”‚   â”œâ”€â”€ HistoryView.swift
â”‚   â”œâ”€â”€ SettingsView.swift
â”‚   â”œâ”€â”€ OnboardingView.swift
â”‚   â””â”€â”€ Components/
â”‚       â””â”€â”€ WaveformView.swift
â”œâ”€â”€ Features/
â”‚   â”œâ”€â”€ Dashboard/
â”‚   â””â”€â”€ AudioTest/
â””â”€â”€ Resources/
    â”œâ”€â”€ AnswerQualityModel.mlmodel
    â””â”€â”€ Localizable.xcstrings
```

---

## The ML Magic ğŸª„

The app includes a custom CoreML model (`AnswerQualityModel.mlmodel`) trained to evaluate interview answer quality. It considers:

- **Clarity** â€” How clear and structured is the response?
- **Confidence** â€” Does the speaker sound confident?
- **Technical Depth** â€” Is there substance to the answer?
- **Pace** â€” Is the speaking rate appropriate?

The model was trained on interview transcript data and outputs scores from 0-100 for each dimension.

---

## Getting Started ğŸš€

### Requirements

- iOS 17.0+
- Xcode 15.0+
- iPhone with microphone (Simulator has limited audio support :7)

### Setup

1. Clone the repository
2. Open `EchoInterview.xcodeproj` in Xcode
3. Build and run on a physical device (recommended for full audio/speech functionality)
4. Grant microphone and speech recognition permissions when prompted

### First Launch

The app includes an onboarding flow that will:
1. Welcome you to the app
2. Request microphone permission
3. Request speech recognition permission
4. Test your voice with a quick recording
5. Get you ready to practice!

---

## âš ï¸ Disclaimer

**This is a practice/learning project!** 

EchoInterview was built as an exploration of modern iOS development patterns including:
- SwiftUI animations
- On-device ML/AI
- Speech and audio processing

### What This Means:

- ğŸ”¨ **Work in Progress** â€” Features may be incomplete or buggy
- ğŸ§ª **Experimental** â€” Some implementations are exploratory
- ğŸ“š **Learning Exercise** â€” Code prioritizes learning over production-readiness
- ğŸš§ **Rough Edges** â€” UI/UX could use more polish
- ğŸ› **Known Issues** â€” There are bugs, and that's okay!

This project is **not** intended for production use or App Store distribution. It's a sandbox for learning and experimentation.

---

## What I Learned ğŸ“–

Building this project provided hands-on experience with:

- Integrating multiple Apple frameworks (Speech, AVFoundation, CoreML, NaturalLanguage)
- Managing complex async flows with Swift Concurrency
- Building responsive UI with SwiftUI animations
- Training and deploying CoreML models
- Using Foundation Models for on-device AI
- Implementing proper MVVM architecture with `@Observable`
- Handling audio format compatibility issues
- SwiftData for modern persistence

---

## Future Ideas ğŸ’­

If this were to become a real app:

- [ ] More interview question categories (behavioral, technical, case studies)
- [ ] Video recording for body language analysis
- [ ] Progress tracking over time
- [ ] Mock interview sessions with time limits
- [ ] Export/share session reports
- [ ] iPad support
- [ ] watchOS companion for quick practice

---

## Contributing ğŸ¤

This is a personal learning project, but if you'd like to:
- Report a bug
- Suggest an improvement
- Share feedback

Feel free to open an issue or reach out!

---

## License ğŸ“„

This project is for educational purposes. Feel free to explore, learn from, and build upon it.

---

## Final Thoughts ğŸ’­

EchoInterview started as a "what if" experiment â€” what if your phone could be your interview coach? While it's far from perfect, building it was a fantastic journey through modern iOS development.

Whether you're here to learn, to contribute, or just curious about how it all works â€” welcome! ğŸ‰

*Now go practice that interview and land your dream job!* ğŸš€

---

<p align="center">
  <i>Built with â˜• and curiosity</i>
</p>
